This chapter focuses on describing the main technicalities of machine learning algorithms that are commonly used in RS and shall be tested in this research. Sparsity concepts are also presented in order to establish key definitions that support the proposed framework to evaluate sparsity effects on recommendation quality.

\section{Neighborhood Models}

As aforementioned in Section \ref{sec:CF}, neighborhood-based models use the principle of \textit{word-of-mouth} where the feedbacks of like-minded users are employed to compute item preferences on a cluster of peers. Since similarity between two entities are at the core of these models, two main approaches are described: the item- and user-based clustering.

User-based approach was applied in the early CF techniques, where users similarities were computed to estimate feedback prediction \cite{1999AlgorithmicFramework}. However, not only does user-user similarity matrices frequently present high dimensionality, but also does not provide helpful explanations on recommendations. To overcome these drawbacks, item-item similarity matrix is used instead, since the fact that usually $|\mathcal{U}| < |\mathcal{I}|$ results in a lower dimension similarity matrix \cite{2001sarwar}. With this perspective, the item-based clustering method is formally described as follows.

Given the set $\mathcal{N}_i(u)$ of $k$ most similar users to $u$ who have interacted with item $i$, $r_{ui}$ can be estimated according to Equation \ref{eq:itemknn}

\begin{equation} 
    \label{eq:itemknn}
    \hat{r}_{ui} = b_{ui} + \frac{\sum_{v \in \mathcal{N}_i(u)} \rho(u,v)\cdot (r_{vi}-b_{vi})}{\sum_{v \in \mathcal{N}_i(u)} \rho(u,v)}
\end{equation} where $\rho(u,v)$ is a similarity measure between users $u$ and $v$. Several similarity measures have been used in this scenario, such as the Pearson correlation coefficient or the cosine similarity \cite{2010Handbook}.

\section{Latent Factor Models}


\subsection{Matrix Factorization}

    Matrix factorization (MF) \abbrev{MF}{Matrix Factorization} models map users and items to a joint latent factor space of dimensionality $f$ such that user-item interactions are modeled as inner products in that space. Formally, the utility matrix $\mathbf{R}$ can be modeled as Equation \ref{eq:MF}
    
    \begin{equation}
        \label{eq:MF}
        \mathbf{R_{|\mathcal{U}| \times |\mathcal{I}|}} = \mathbf{Q}_{|\mathcal{I}| \times f} \mathbf{P}_{f \times |\mathcal{U}|} 
    \end{equation} where each item $i$ and user $u$ are mapped as vectors $\mathbf{q}_i \in \mathbb{R}^f$ and $\mathbf{p}_u \in \mathbb{R}^f$, respectively, and their interaction is given by $r_{ui} = \mathbf{q}^T_i \cdot \mathbf{p}_u$ \cite{2009MFTechniques}.
    
    The goal of the learning algorithm is to estimate the parameters of  $\mathbf{q}_i$ and $\mathbf{p}_u$. However, since most of the user-item interactions in $\mathbf{R}$ are unknown, the algorithm can only take into account the error associated with known entries of the matrix. Furthermore, in this set there are $(|\mathcal{U}|+|\mathcal{I}|)\cdot f$ parameters to be found using at most $|\mathcal{U}|\cdot |\mathcal{I}|$ interactions, which is hardly the usual scenario since users most often interact with a small number of items. As a consequence, the learning algorithm needs to find a great number of parameters using few training samples, making over-fitting a problem to be dealt with \cite{2008ALSWR}.
    
    Mathematically, let $\mathcal{K}$ be the set of $(u,i)$ pairs for which $r_{ui}$ is known. Then, the learning algorithm is designed to solve the following optimization problem: 
    
    \begin{equation}
        \label{eq:mf_min}
        \min_{\mathbf{q}^*, \mathbf{p}^*} \sum_{(u,i) \in \mathcal{K}} (r_{ui} - \mathbf{q}^T_i \cdot \mathbf{p}_u)^2 + \lambda (||\mathbf{q}_i||^2 + ||\mathbf{p}_u||)^2
    \end{equation} where $\lambda$ is a regularization parameter that can be estimated through cross-validation (probabilistic estimation is also proposed in \cite{2007ProbMF}). Two approaches are widely used to solve this optimization problem: the stochastic gradient descent and the alternating least squares. 
    
    By using Stochastic Gradient Descent (SGD) \abbrev{SGD}{Stochastic Gradient Descent} [Ref Simon Funk], the algorithm loops through all user-item pairs in a training set and computes an associated prediction error $e_{ui} \triangleq r_{ui} - \mathbf{q}^T_i \cdot \mathbf{p}_u$, updating the parameters by a magnitude proportional to a learning rate $\alpha$ as shown in Equation \ref{eq:sgd}.
    
    \begin{equation}
        \label{eq:sgd}
            \begin{cases}
            \mathbf{q}_i \leftarrow \mathbf{q}_i + \alpha (e_{ui}\cdot \mathbf{p}_u-\lambda \cdot \mathbf{q}_i) \\
            
            \mathbf{p}_u \leftarrow \mathbf{p}_u + \alpha (e_{ui}\cdot \mathbf{q}_i-\lambda \cdot \mathbf{p}_u)
            \end{cases}
    \end{equation} Although being simpler to implement, this approach is not suitable for parallelization since the learning algorithm needs to loop over all training set several times. This is a major drawback since most RS data sets have massive amount of data. In order to use the computational advantages of distributed systems, the Alternating Least Squares (ALS) \abbrev{ALS}{Alternating Least Squares} approach has been proposed by considering the minimization problem as follows.

    %PCA / SCA / ICA
    
    Due to the fact that both $\mathbf{q}_i$ and $\mathbf{p}_u$ are variables, Equation \ref{eq:mf_min} is not convex, leading to possible local minimum. On the other hand, if one of these variables are fixed, then the problem becomes quadratic and thus can be solved optimally. Consequently, the ALS switches between considering one variable fixed and solving the problem to the other, and then doing the opposite in a second step. The training steps can be summarized as follows \cite{2008ALSWR}:
    
    \begin{itemize}
        \item Step 1: Initialize matrix $\mathbf{P}$;
        \item Step 2: Fix $\mathbf{P}$ and solve $\mathbf{Q}$ by minimizing the objective function;
        \item Step 3: Fix $\mathbf{Q}$ and solve $\mathbf{P}$ by minimizing the objective function similarly;
        \item Step 4: Repeat Steps 2 and 3 until a stopping criterion is satisfied.
    \end{itemize}
    
    Additionally, weighted-$\lambda$-regularized (ALS-WR) is proposed in \cite{2008ALSWR} by modifying the regularization term as in Equation \ref{eq:mf_min_weighted}
    
    \begin{equation}
        \label{eq:mf_min_weighted}
        \min_{\mathbf{q}^*, \mathbf{p}^*} \sum_{(u,i) \in \mathcal{K}} (r_{ui} - \mathbf{q}^T_i \cdot \mathbf{p}_u)^2 + \lambda \Big(\sum_i n(i)||\mathbf{q}_i||^2 + \sum_u n(u)||\mathbf{p}_u||\Big)^2
    \end{equation} where $n(u)$ and $n(i)$ are the total number of interactions of user $u$ and item $i$, respectively.

\subsection{Autoencoders}